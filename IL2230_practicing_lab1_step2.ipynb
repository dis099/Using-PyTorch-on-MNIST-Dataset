{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1.],\n",
      "        [1., 1.]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "x = torch.ones(2, 2, requires_grad=True)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1.],\n",
      "        [1., 1.]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3., 3.],\n",
      "        [3., 3.]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "y = x + 2\n",
    "print(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<AddBackward0 object at 0x000001D9A624C748>\n"
     ]
    }
   ],
   "source": [
    "print(y.grad_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[27., 27.],\n",
      "        [27., 27.]], grad_fn=<MulBackward0>) tensor(27., grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "z = y*y*3\n",
    "out = z.mean()\n",
    "print(z, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "True\n",
      "<SumBackward0 object at 0x000001D9A624CC50>\n"
     ]
    }
   ],
   "source": [
    "a = torch.randn(2, 2)\n",
    "a = ((a * 3) / (a - 1))\n",
    "print(a.requires_grad)\n",
    "a.requires_grad_(True)\n",
    "print(a.requires_grad)\n",
    "b = (a * a).sum()\n",
    "print(b.grad_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "out.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[4.5000, 4.5000],\n",
      "        [4.5000, 4.5000]])\n"
     ]
    }
   ],
   "source": [
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([   -5.2940,  -538.7870, -1071.1195], grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(3, requires_grad=True)\n",
    "y = x * 2\n",
    "while y.data.norm() < 1000:\n",
    "    y = y * 2\n",
    "\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.3300, -1.5903,  3.3435], grad_fn=<MulBackward0>)\n",
      "tensor([ 168.9812, -814.2557, 1711.8734], grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(3, requires_grad=True)\n",
    "y = x * 2\n",
    "print(y)\n",
    "while y.data.norm() < 1000:\n",
    "    y = y * 2\n",
    "\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 1.0336, -1.5695, -0.6768], grad_fn=<MulBackward0>)\n",
      "tensor([ 1.0336, -1.5695, -0.6768], grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(3, requires_grad=True)\n",
    "y = x * 2\n",
    "print(y)\n",
    "y.data.norm()\n",
    "print(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2.3611, 2.2934, 0.9235], grad_fn=<MulBackward0>)\n",
      "tensor([2.3611, 2.2934, 0.9235], grad_fn=<MulBackward0>)\n",
      "tensor([1208.8994, 1174.2330,  472.8571], grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(3, requires_grad=True)\n",
    "\n",
    "y = x * 2\n",
    "print(y)\n",
    "y.data.norm()\n",
    "print(y)\n",
    "while y.data.norm() < 1000:\n",
    "    y = y * 2\n",
    "\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-1.0654,  2.6875, -1.7169], grad_fn=<MulBackward0>)\n",
      "tensor([-1.0654,  2.6875, -1.7169], grad_fn=<MulBackward0>)\n",
      "tensor([-545.5050, 1376.0189, -879.0717], grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(3, requires_grad=True)\n",
    "\n",
    "y = x * 2\n",
    "print(y)\n",
    "y.data.norm() < 1000\n",
    "print(y)\n",
    "while y.data.norm() < 1000:\n",
    "    y = y * 2\n",
    "\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = torch.tensor([0.1, 1.0, 0.0001], dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.0000e-01, 1.0000e+00, 1.0000e-04])\n"
     ]
    }
   ],
   "source": [
    "print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.backward(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.0240e+02, 1.0240e+03, 1.0240e-01])\n"
     ]
    }
   ],
   "source": [
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "print((x ** 2).requires_grad)\n",
    "\n",
    "with torch.no_grad():\n",
    "    print((x ** 2).requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "print(x.requires_grad)\n",
    "print((x ** 2).requires_grad)\n",
    "\n",
    "with torch.no_grad():\n",
    "    print((x ** 2).requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=576, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # 1 input image channel, 6 output channels, 3x3 square convolution\n",
    "        # kernel\n",
    "        self.conv1 = nn.Conv2d(1, 6, 3)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 3)\n",
    "        # an affine operation: y = Wx + b\n",
    "        self.fc1 = nn.Linear(16 * 6 * 6, 120)  # 6*6 from image dimension\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Max pooling over a (2, 2) window\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
    "        # If the size is a square you can only specify a single number\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features\n",
    "\n",
    "\n",
    "net = Net()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "torch.Size([6, 1, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "params = list(net.parameters())\n",
    "print(len(params))\n",
    "print(params[0].size())  # conv1's .weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.1014,  0.0064,  0.0236,  0.0409,  0.0567,  0.0141, -0.0658,  0.0256,\n",
      "         -0.0724, -0.0314]], grad_fn=<AddmmBackward>)\n"
     ]
    }
   ],
   "source": [
    "input = torch.randn(1, 1, 32, 32)\n",
    "out = net(input)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parameter containing:\n",
      "tensor([[[[ 0.0632,  0.0453, -0.0489],\n",
      "          [-0.2559,  0.0908,  0.3287],\n",
      "          [ 0.2660, -0.2663, -0.1560]]],\n",
      "\n",
      "\n",
      "        [[[-0.1643,  0.0426, -0.0159],\n",
      "          [-0.3157, -0.2607,  0.1475],\n",
      "          [ 0.2444,  0.2989,  0.2903]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2286, -0.0669,  0.2363],\n",
      "          [-0.3136, -0.1829,  0.0984],\n",
      "          [-0.0921,  0.0623,  0.1353]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2301, -0.3017,  0.0786],\n",
      "          [-0.0649,  0.2608,  0.2206],\n",
      "          [ 0.0581, -0.0880,  0.1821]]],\n",
      "\n",
      "\n",
      "        [[[-0.1685, -0.2751, -0.0428],\n",
      "          [-0.2378, -0.0657, -0.0214],\n",
      "          [ 0.2211, -0.0367, -0.0107]]],\n",
      "\n",
      "\n",
      "        [[[ 0.3211,  0.0787, -0.2549],\n",
      "          [ 0.2323,  0.2537,  0.0494],\n",
      "          [ 0.0216,  0.2494,  0.2275]]]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.1725,  0.0083, -0.1488,  0.2210,  0.1619, -0.1759],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([[[[-5.4536e-03, -7.7456e-02,  2.8291e-03],\n",
      "          [ 1.1570e-01,  2.4970e-02, -1.0426e-01],\n",
      "          [-4.7416e-02, -7.5992e-02, -1.2572e-01]],\n",
      "\n",
      "         [[-1.1595e-01,  6.0275e-02, -1.3331e-01],\n",
      "          [ 3.5219e-02,  6.7142e-02, -1.7901e-02],\n",
      "          [ 1.7715e-02, -6.5386e-02,  5.8101e-02]],\n",
      "\n",
      "         [[ 5.0885e-03,  1.1932e-01,  9.0099e-02],\n",
      "          [ 1.3018e-01,  8.0707e-02, -9.6964e-02],\n",
      "          [ 9.0632e-02, -5.3640e-02,  6.3629e-02]],\n",
      "\n",
      "         [[-6.7457e-02,  3.0124e-02, -3.7652e-03],\n",
      "          [ 1.6715e-02, -1.0749e-01, -5.9158e-02],\n",
      "          [ 8.5304e-02, -1.6029e-02,  1.1645e-01]],\n",
      "\n",
      "         [[ 3.5344e-02,  2.0502e-02, -8.7243e-02],\n",
      "          [ 1.3524e-01,  3.4794e-03, -4.2650e-02],\n",
      "          [-7.9619e-02, -9.7116e-02, -7.1859e-02]],\n",
      "\n",
      "         [[-9.0934e-02, -1.1630e-01, -4.8491e-02],\n",
      "          [ 3.5484e-02, -1.3181e-01, -9.3738e-03],\n",
      "          [-1.1050e-01, -1.1689e-01, -4.7659e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 6.0202e-02, -2.4622e-02, -1.2673e-01],\n",
      "          [-1.0255e-01,  2.8727e-02, -9.3214e-02],\n",
      "          [ 7.9671e-02, -2.2729e-02, -5.8160e-02]],\n",
      "\n",
      "         [[-1.1387e-01, -1.0082e-01,  3.4925e-02],\n",
      "          [-6.6954e-02, -7.0159e-02, -1.3078e-01],\n",
      "          [ 6.1176e-02, -5.8890e-02, -1.2944e-01]],\n",
      "\n",
      "         [[ 6.4799e-02, -1.3167e-01,  1.1029e-01],\n",
      "          [ 1.6557e-02, -5.1446e-03,  1.9707e-03],\n",
      "          [ 1.2678e-01, -6.9593e-02, -8.8333e-02]],\n",
      "\n",
      "         [[ 1.2865e-01,  1.3047e-01,  5.9527e-02],\n",
      "          [-4.8400e-02, -1.8221e-02, -7.7374e-02],\n",
      "          [ 1.3004e-01, -2.2944e-02, -6.5321e-02]],\n",
      "\n",
      "         [[-1.2331e-01,  1.1566e-01, -5.8365e-02],\n",
      "          [-4.6354e-02,  2.8285e-02, -1.0189e-01],\n",
      "          [-7.8400e-02,  1.3489e-01, -2.5977e-02]],\n",
      "\n",
      "         [[ 1.2165e-01,  1.1259e-01, -1.2480e-01],\n",
      "          [-1.0781e-02,  1.2835e-01, -6.4801e-02],\n",
      "          [ 6.0711e-03,  6.2108e-02, -5.9730e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 3.9464e-02,  4.7969e-02, -4.6449e-02],\n",
      "          [ 3.4618e-02, -7.6961e-02, -7.7740e-02],\n",
      "          [ 2.7544e-02, -3.2435e-02, -8.4009e-02]],\n",
      "\n",
      "         [[ 9.5487e-04,  9.8955e-02, -1.1510e-01],\n",
      "          [-1.3147e-01, -1.2039e-01, -7.8709e-02],\n",
      "          [ 1.1128e-01, -8.7143e-02, -2.2627e-02]],\n",
      "\n",
      "         [[-8.1844e-02, -8.0810e-02,  4.6223e-03],\n",
      "          [-5.2096e-02,  1.0251e-02,  5.0113e-02],\n",
      "          [-6.9125e-02,  5.4865e-02, -5.3764e-02]],\n",
      "\n",
      "         [[-6.6273e-02,  6.8179e-02,  1.1065e-01],\n",
      "          [-1.3398e-01,  2.3797e-02, -1.1552e-01],\n",
      "          [-2.3936e-02, -8.3927e-02, -1.7857e-02]],\n",
      "\n",
      "         [[ 8.0811e-02, -6.5405e-02, -6.3824e-02],\n",
      "          [ 8.5393e-02,  1.0560e-01, -9.4498e-02],\n",
      "          [ 1.1000e-01,  1.1977e-01,  5.6570e-02]],\n",
      "\n",
      "         [[-3.4639e-02, -1.4056e-02, -1.1842e-01],\n",
      "          [ 7.6377e-02, -4.0152e-02, -1.0645e-01],\n",
      "          [ 6.8965e-02, -4.2974e-02,  1.3486e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 2.6701e-02,  8.0206e-02,  3.7936e-02],\n",
      "          [ 4.3411e-02,  8.9756e-02, -2.7196e-02],\n",
      "          [ 1.9551e-02,  1.3294e-01, -2.0649e-02]],\n",
      "\n",
      "         [[-8.6750e-02, -2.7995e-02,  1.3137e-01],\n",
      "          [ 1.1091e-01, -1.1823e-01, -7.2927e-02],\n",
      "          [-1.0637e-01,  3.9275e-02,  7.7235e-02]],\n",
      "\n",
      "         [[-4.1552e-02, -9.7183e-02,  6.3835e-02],\n",
      "          [ 3.9322e-02,  1.0252e-02, -1.3244e-01],\n",
      "          [ 1.0896e-01,  1.0788e-01,  3.5947e-02]],\n",
      "\n",
      "         [[-1.1804e-01, -1.2657e-01, -4.1917e-02],\n",
      "          [ 2.0776e-02,  8.5236e-02,  6.4601e-02],\n",
      "          [ 1.1917e-01, -5.9803e-02,  1.1703e-01]],\n",
      "\n",
      "         [[-3.1399e-03,  3.7886e-02,  1.0123e-01],\n",
      "          [ 3.7984e-02, -1.2936e-01, -5.6856e-02],\n",
      "          [-1.8043e-02,  1.2521e-01,  1.0238e-01]],\n",
      "\n",
      "         [[-1.2377e-01,  1.3141e-01, -1.7102e-02],\n",
      "          [-9.5280e-02,  1.0711e-01,  4.0584e-02],\n",
      "          [-1.1168e-01, -1.5428e-02, -3.2809e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.2847e-01,  2.8573e-02,  2.2803e-04],\n",
      "          [ 9.9557e-02,  1.0968e-01,  1.1680e-02],\n",
      "          [-1.3500e-01,  5.3799e-02, -3.4753e-02]],\n",
      "\n",
      "         [[-4.1106e-03,  4.0546e-02, -3.9669e-02],\n",
      "          [ 4.1325e-02,  1.6989e-02, -1.3276e-01],\n",
      "          [ 1.2225e-01, -1.2229e-01, -6.9817e-02]],\n",
      "\n",
      "         [[-9.7613e-02,  5.9471e-02,  3.3095e-02],\n",
      "          [-5.3721e-02,  1.2728e-01,  8.2437e-02],\n",
      "          [-8.2138e-02,  9.9021e-02,  6.9873e-02]],\n",
      "\n",
      "         [[ 1.2340e-01,  6.8887e-02,  8.7989e-02],\n",
      "          [ 1.0563e-01, -6.6189e-03, -1.0787e-01],\n",
      "          [-6.2537e-02, -7.7791e-02,  2.6997e-02]],\n",
      "\n",
      "         [[ 9.8434e-02,  9.0758e-02,  1.0723e-01],\n",
      "          [ 7.8219e-02, -1.5965e-02, -7.6277e-02],\n",
      "          [ 9.7056e-03,  1.2347e-01,  1.3438e-01]],\n",
      "\n",
      "         [[-3.8318e-02,  1.1759e-01,  2.5575e-02],\n",
      "          [ 1.1090e-01, -4.8462e-02,  2.4593e-03],\n",
      "          [-9.3570e-02,  1.2766e-01,  3.4250e-02]]],\n",
      "\n",
      "\n",
      "        [[[-2.6549e-02,  4.8595e-02, -5.9944e-02],\n",
      "          [ 6.8457e-02, -4.5755e-02, -1.3474e-01],\n",
      "          [-2.2208e-02,  6.8725e-02,  8.5161e-02]],\n",
      "\n",
      "         [[ 6.0767e-05,  7.6575e-02, -5.9422e-02],\n",
      "          [ 2.6883e-02, -2.8823e-02,  1.1165e-01],\n",
      "          [ 3.2940e-02,  1.0239e-01, -1.0850e-01]],\n",
      "\n",
      "         [[-4.0707e-03,  4.8733e-02, -7.3411e-02],\n",
      "          [-9.3892e-02,  4.1834e-02, -9.8317e-02],\n",
      "          [ 6.3290e-02,  1.3183e-01,  3.8746e-02]],\n",
      "\n",
      "         [[ 1.1147e-01,  1.0620e-01,  9.6638e-02],\n",
      "          [-8.0731e-02,  9.1402e-02, -6.8562e-02],\n",
      "          [-6.7696e-02,  1.2185e-01, -4.6820e-02]],\n",
      "\n",
      "         [[-1.0093e-01, -1.2607e-01, -3.4870e-02],\n",
      "          [-8.7229e-02,  1.1914e-01, -4.0490e-02],\n",
      "          [-3.6370e-02, -7.3232e-02,  7.1367e-02]],\n",
      "\n",
      "         [[ 7.4379e-02, -9.6895e-02,  1.0536e-02],\n",
      "          [ 1.1772e-01, -1.0684e-01,  1.2720e-01],\n",
      "          [-5.6263e-03, -8.1442e-02,  4.5884e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 1.9504e-03,  1.0381e-01,  1.0472e-01],\n",
      "          [-5.3046e-02, -9.3037e-02, -6.6058e-02],\n",
      "          [-1.0334e-01,  5.2146e-03,  1.0820e-01]],\n",
      "\n",
      "         [[ 1.1450e-01,  1.2225e-01,  1.3511e-01],\n",
      "          [-1.2971e-01,  2.2760e-03, -2.7471e-02],\n",
      "          [-4.1714e-02,  7.0603e-02,  1.2774e-01]],\n",
      "\n",
      "         [[ 1.8816e-02,  1.2766e-01, -6.3587e-02],\n",
      "          [ 9.5474e-02,  8.4360e-02,  1.3296e-01],\n",
      "          [-5.8381e-02, -5.7194e-02,  7.3536e-02]],\n",
      "\n",
      "         [[ 4.8251e-02,  8.3362e-02, -4.2665e-02],\n",
      "          [ 1.0687e-01,  3.6126e-02, -7.5604e-02],\n",
      "          [ 8.0989e-02, -1.0295e-01, -2.1778e-02]],\n",
      "\n",
      "         [[-4.8066e-02,  1.6439e-02,  2.0227e-02],\n",
      "          [ 1.1651e-01, -1.2075e-01,  2.2715e-02],\n",
      "          [ 1.5783e-02, -1.2774e-01, -5.2285e-03]],\n",
      "\n",
      "         [[-3.5550e-03, -7.2278e-02, -8.4656e-02],\n",
      "          [ 4.9426e-02,  7.5537e-02, -1.0501e-01],\n",
      "          [ 1.1581e-01,  1.1536e-01, -1.1712e-01]]],\n",
      "\n",
      "\n",
      "        [[[-8.9408e-02,  1.3405e-01,  7.2652e-02],\n",
      "          [-4.8813e-02, -4.4217e-02,  1.2119e-01],\n",
      "          [-7.9475e-02, -6.9737e-02,  5.2481e-03]],\n",
      "\n",
      "         [[-3.1893e-02,  1.1335e-01, -6.2894e-03],\n",
      "          [ 7.7085e-02, -1.2623e-01, -8.9175e-02],\n",
      "          [-1.2371e-01, -7.9643e-02,  1.0848e-01]],\n",
      "\n",
      "         [[ 1.0099e-01,  2.4813e-02,  1.0830e-02],\n",
      "          [-1.0455e-01,  4.6435e-02, -7.3740e-02],\n",
      "          [-6.9655e-04,  6.8886e-02,  8.4524e-03]],\n",
      "\n",
      "         [[-3.7144e-02,  9.5315e-02,  9.4445e-02],\n",
      "          [-9.2517e-02,  7.6329e-03,  1.1701e-01],\n",
      "          [ 2.1503e-02,  6.3384e-02,  2.4548e-02]],\n",
      "\n",
      "         [[-4.6044e-02, -1.2445e-01,  8.7211e-02],\n",
      "          [ 3.9610e-03, -6.7322e-02,  6.2135e-02],\n",
      "          [-1.3847e-02, -8.3870e-02, -1.0863e-01]],\n",
      "\n",
      "         [[-1.0393e-01, -5.5176e-04,  2.8050e-02],\n",
      "          [ 1.0924e-01,  1.0805e-02, -6.7372e-02],\n",
      "          [-9.0508e-02,  2.6828e-02,  8.7029e-02]]],\n",
      "\n",
      "\n",
      "        [[[-7.2792e-02, -1.7970e-02, -1.1817e-01],\n",
      "          [ 9.1196e-02,  1.9309e-02, -2.0400e-02],\n",
      "          [ 2.8554e-02,  2.5061e-02, -2.1771e-02]],\n",
      "\n",
      "         [[-3.1655e-02, -8.5420e-02,  6.2954e-02],\n",
      "          [-1.3439e-01,  4.7850e-02, -1.2441e-01],\n",
      "          [-1.2216e-02,  2.6710e-03, -1.4060e-02]],\n",
      "\n",
      "         [[ 6.7340e-02, -7.0810e-02,  6.0208e-02],\n",
      "          [-8.0375e-02,  6.7175e-02, -1.0865e-02],\n",
      "          [ 1.2801e-01, -3.2844e-02,  1.6712e-02]],\n",
      "\n",
      "         [[ 1.5874e-02,  1.1663e-01, -9.0378e-02],\n",
      "          [ 3.8185e-03,  3.0403e-02, -1.0460e-01],\n",
      "          [-5.7073e-02, -8.5387e-02,  1.0682e-01]],\n",
      "\n",
      "         [[ 9.0681e-02,  2.1219e-02, -1.0356e-01],\n",
      "          [-5.5106e-02,  4.8404e-02, -4.5638e-02],\n",
      "          [-1.1344e-01,  4.0186e-02,  6.0326e-02]],\n",
      "\n",
      "         [[-9.4203e-02, -6.0639e-02,  1.0878e-01],\n",
      "          [ 3.1774e-03, -1.0163e-01,  6.9560e-02],\n",
      "          [ 2.7885e-02,  5.7961e-02,  1.2857e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 9.2764e-02, -3.4907e-02, -1.2854e-01],\n",
      "          [-1.2234e-01, -4.1401e-03,  1.1915e-01],\n",
      "          [ 2.5969e-03,  1.1213e-01,  1.1962e-01]],\n",
      "\n",
      "         [[-7.6679e-02, -2.6973e-02,  1.0920e-02],\n",
      "          [-5.6296e-02,  1.1430e-01,  1.5911e-02],\n",
      "          [ 7.6423e-02,  9.7519e-02,  8.9168e-02]],\n",
      "\n",
      "         [[ 1.0750e-01, -3.0192e-02,  1.8931e-02],\n",
      "          [ 5.6639e-02, -7.4836e-02,  1.1120e-01],\n",
      "          [-6.3216e-02, -7.5786e-02,  1.1155e-01]],\n",
      "\n",
      "         [[ 1.0559e-01, -1.0642e-01,  1.6129e-02],\n",
      "          [ 6.7493e-02, -6.9421e-02,  1.0612e-01],\n",
      "          [ 3.2020e-02,  6.7203e-02, -3.2117e-02]],\n",
      "\n",
      "         [[-7.5125e-02,  4.3353e-02, -1.0702e-01],\n",
      "          [ 2.8230e-02,  4.4617e-02,  5.0463e-03],\n",
      "          [-9.5515e-02,  3.8101e-02, -2.6488e-02]],\n",
      "\n",
      "         [[ 8.7474e-02, -1.1947e-01, -3.7432e-03],\n",
      "          [ 8.8495e-02,  1.6452e-02,  4.8242e-02],\n",
      "          [-4.1657e-02,  9.5094e-02, -1.1925e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.2135e-01, -1.0665e-02, -9.8219e-02],\n",
      "          [-6.1447e-02, -9.0017e-02,  8.2064e-02],\n",
      "          [ 9.0176e-02,  8.4848e-02,  2.0085e-02]],\n",
      "\n",
      "         [[-1.1923e-01, -1.4566e-02, -1.1459e-01],\n",
      "          [ 9.5686e-02, -5.3224e-02, -8.2563e-02],\n",
      "          [ 5.5481e-02,  4.1019e-03, -3.6806e-02]],\n",
      "\n",
      "         [[-3.1154e-02,  8.6952e-02, -1.3216e-01],\n",
      "          [-1.8789e-02, -4.1830e-02, -4.4455e-02],\n",
      "          [ 1.2343e-01, -9.5645e-02,  5.8725e-02]],\n",
      "\n",
      "         [[ 1.4736e-02, -1.0396e-01, -1.9104e-02],\n",
      "          [-8.7601e-02,  1.3272e-01, -3.6228e-02],\n",
      "          [ 1.1495e-01, -5.2086e-02, -1.3298e-01]],\n",
      "\n",
      "         [[-3.1580e-02,  2.0779e-02,  1.2357e-02],\n",
      "          [ 2.3295e-02,  2.3559e-02,  5.5613e-02],\n",
      "          [ 5.4977e-02,  1.5278e-03,  2.0506e-02]],\n",
      "\n",
      "         [[ 1.3060e-01, -5.6652e-02,  3.9111e-02],\n",
      "          [-1.1807e-02,  8.8130e-02, -1.2674e-01],\n",
      "          [-9.1865e-03,  5.4458e-03,  1.4327e-02]]],\n",
      "\n",
      "\n",
      "        [[[-6.8567e-02, -1.3047e-01, -4.0471e-02],\n",
      "          [-2.8844e-02, -1.1046e-01,  4.5127e-02],\n",
      "          [ 1.1824e-01, -4.2063e-02, -4.6714e-02]],\n",
      "\n",
      "         [[ 3.3774e-02, -6.0339e-02, -8.5046e-02],\n",
      "          [-1.0570e-01, -1.2604e-01,  5.8832e-02],\n",
      "          [ 9.7915e-02,  8.5569e-02,  2.1409e-03]],\n",
      "\n",
      "         [[ 3.5372e-02,  6.4328e-02, -5.8000e-02],\n",
      "          [ 1.2243e-01, -9.9040e-02,  1.6505e-02],\n",
      "          [ 3.5719e-02,  1.0865e-01, -1.1881e-01]],\n",
      "\n",
      "         [[ 1.2763e-01,  7.4395e-03, -4.8685e-02],\n",
      "          [-7.3626e-02, -6.0292e-02, -1.4449e-02],\n",
      "          [ 7.4671e-02,  1.7853e-02,  8.4444e-02]],\n",
      "\n",
      "         [[ 1.0317e-01,  2.3366e-02, -1.1142e-01],\n",
      "          [ 1.6172e-02, -6.5690e-04,  2.2768e-02],\n",
      "          [-4.4336e-02, -6.6327e-02, -3.9427e-02]],\n",
      "\n",
      "         [[-3.8770e-02, -8.1495e-02,  5.4299e-02],\n",
      "          [-1.6877e-03, -4.0430e-02,  7.4010e-02],\n",
      "          [-5.3845e-02, -6.5808e-02, -1.3468e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 2.6202e-02,  7.5544e-02, -1.1991e-01],\n",
      "          [ 9.7151e-02, -2.9785e-02,  1.2998e-01],\n",
      "          [-3.4640e-02, -1.1965e-01, -8.7148e-03]],\n",
      "\n",
      "         [[ 2.3033e-02,  7.0581e-03, -1.2951e-02],\n",
      "          [ 7.4246e-02, -4.6060e-02,  3.6708e-02],\n",
      "          [-1.2811e-01,  2.9414e-02,  6.5391e-02]],\n",
      "\n",
      "         [[-2.7762e-02, -1.2422e-02,  6.3945e-02],\n",
      "          [-1.2711e-01,  1.3554e-01, -8.3184e-02],\n",
      "          [ 8.3290e-02,  9.8438e-02, -7.7389e-02]],\n",
      "\n",
      "         [[-1.3293e-01, -1.2150e-01,  1.2786e-01],\n",
      "          [ 2.6507e-02, -2.9770e-03,  6.0048e-02],\n",
      "          [-9.2793e-02, -7.6019e-03, -8.3837e-02]],\n",
      "\n",
      "         [[ 1.1185e-01, -5.3133e-02, -4.4312e-02],\n",
      "          [ 7.2847e-02,  1.9340e-02, -7.5523e-02],\n",
      "          [-1.9774e-02, -9.2203e-02,  1.0968e-01]],\n",
      "\n",
      "         [[ 7.8735e-02, -7.5485e-02,  8.1185e-02],\n",
      "          [ 1.2567e-01, -2.3065e-02,  6.6252e-02],\n",
      "          [-1.2179e-02,  1.2609e-01, -9.5821e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 7.0136e-02, -1.0684e-01, -9.7593e-02],\n",
      "          [-9.3936e-02, -5.8642e-02,  8.5901e-02],\n",
      "          [-1.3560e-01, -1.0217e-01,  9.7762e-02]],\n",
      "\n",
      "         [[-6.1416e-03, -9.0019e-02, -2.6571e-02],\n",
      "          [ 2.2909e-02, -1.5751e-02, -3.4956e-02],\n",
      "          [-1.0313e-01,  6.8284e-02,  1.0611e-01]],\n",
      "\n",
      "         [[-1.8077e-02,  1.0663e-01, -2.9476e-02],\n",
      "          [ 8.7466e-02, -1.1856e-01, -5.3751e-02],\n",
      "          [ 3.7892e-02, -1.1922e-02, -7.5695e-03]],\n",
      "\n",
      "         [[ 9.1922e-04,  7.7516e-03, -1.4187e-02],\n",
      "          [-6.6247e-02, -1.0009e-01,  1.2850e-01],\n",
      "          [ 2.0174e-02,  1.3372e-01,  1.0966e-01]],\n",
      "\n",
      "         [[ 4.1100e-03, -3.9406e-02,  3.1912e-04],\n",
      "          [-9.3836e-02, -5.2184e-02,  2.7362e-02],\n",
      "          [ 4.4912e-02, -1.2191e-01,  6.1731e-02]],\n",
      "\n",
      "         [[-6.4974e-02, -7.2391e-02, -3.5195e-02],\n",
      "          [ 1.1166e-01, -4.7780e-02,  2.0582e-02],\n",
      "          [-9.6598e-02,  2.7424e-02,  3.8278e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 5.4444e-02,  4.8477e-02,  5.7006e-02],\n",
      "          [ 1.1558e-01, -4.3729e-02,  4.7206e-02],\n",
      "          [-1.2097e-01, -1.3233e-01,  5.7321e-02]],\n",
      "\n",
      "         [[-3.8114e-02,  2.9067e-03,  8.4542e-02],\n",
      "          [-3.7409e-02, -3.8212e-02, -2.0380e-02],\n",
      "          [-7.6228e-02, -1.1956e-03,  3.6382e-02]],\n",
      "\n",
      "         [[ 9.2668e-02, -5.0254e-02,  4.3741e-02],\n",
      "          [ 8.8392e-04,  2.9525e-02, -1.0049e-01],\n",
      "          [ 3.5561e-02, -8.9984e-04,  8.7731e-02]],\n",
      "\n",
      "         [[ 9.2218e-02,  1.0699e-01, -1.0931e-01],\n",
      "          [-6.0445e-02, -4.9980e-02, -2.9395e-03],\n",
      "          [-6.3218e-02,  6.7018e-02, -1.3142e-01]],\n",
      "\n",
      "         [[ 5.6367e-02,  7.4761e-02, -9.2058e-02],\n",
      "          [-5.6599e-02, -9.5128e-02,  5.8605e-02],\n",
      "          [ 1.1549e-01, -1.2259e-01, -5.9968e-02]],\n",
      "\n",
      "         [[ 9.7144e-02, -2.0217e-02,  1.3486e-01],\n",
      "          [-1.1486e-01, -1.2893e-01,  1.0423e-01],\n",
      "          [ 8.9238e-02, -8.3505e-02, -1.3346e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.1454e-01,  6.8834e-02, -1.0383e-01],\n",
      "          [ 5.5416e-02, -4.9038e-02,  7.3355e-02],\n",
      "          [ 1.6595e-02, -5.5423e-02, -1.0403e-01]],\n",
      "\n",
      "         [[ 1.8724e-03, -6.3119e-02, -1.2001e-01],\n",
      "          [ 3.6873e-02,  1.9861e-02, -1.2170e-01],\n",
      "          [-8.1042e-02,  1.3389e-01, -1.2837e-01]],\n",
      "\n",
      "         [[ 2.1800e-02,  8.7286e-02, -1.1227e-01],\n",
      "          [-4.4591e-02, -9.3693e-02, -9.8883e-03],\n",
      "          [-1.3533e-01, -9.4033e-02, -1.3094e-01]],\n",
      "\n",
      "         [[-6.5707e-02,  1.0628e-01,  9.4844e-02],\n",
      "          [-1.0789e-01, -1.2023e-01,  9.8090e-02],\n",
      "          [-3.2727e-03,  8.9418e-02,  9.2935e-02]],\n",
      "\n",
      "         [[ 3.7951e-02,  4.4187e-02,  7.6166e-02],\n",
      "          [-4.0752e-02, -1.3447e-01, -5.9331e-02],\n",
      "          [ 3.9748e-02,  9.8322e-02,  5.0941e-02]],\n",
      "\n",
      "         [[-4.8476e-02,  2.2031e-02,  4.3786e-02],\n",
      "          [-8.9271e-02, -7.5982e-02,  2.5095e-02],\n",
      "          [-4.0454e-02, -5.9411e-02, -1.2689e-01]]]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.0792,  0.1263,  0.0762,  0.0529, -0.0365,  0.0883,  0.1002, -0.0955,\n",
      "        -0.0114, -0.0748, -0.0389,  0.0898, -0.1108,  0.0207, -0.1122,  0.1167],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([[-0.0088,  0.0392, -0.0061,  ...,  0.0323, -0.0146,  0.0132],\n",
      "        [ 0.0120, -0.0188, -0.0058,  ...,  0.0371, -0.0069, -0.0357],\n",
      "        [-0.0032, -0.0275, -0.0416,  ...,  0.0092, -0.0394, -0.0055],\n",
      "        ...,\n",
      "        [ 0.0151, -0.0109,  0.0221,  ..., -0.0303,  0.0091, -0.0108],\n",
      "        [ 0.0292, -0.0206,  0.0299,  ...,  0.0054, -0.0230, -0.0331],\n",
      "        [ 0.0346, -0.0173, -0.0201,  ..., -0.0243, -0.0416, -0.0100]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([ 0.0006,  0.0412,  0.0251,  0.0124,  0.0298, -0.0165,  0.0302,  0.0113,\n",
      "        -0.0064,  0.0237,  0.0203, -0.0393, -0.0280,  0.0251,  0.0176, -0.0138,\n",
      "         0.0264, -0.0331,  0.0360, -0.0410,  0.0333, -0.0223, -0.0032, -0.0110,\n",
      "         0.0110,  0.0409, -0.0088, -0.0155,  0.0269,  0.0223, -0.0217, -0.0014,\n",
      "        -0.0146, -0.0106,  0.0338,  0.0319, -0.0126, -0.0027,  0.0211,  0.0174,\n",
      "        -0.0221, -0.0202, -0.0133,  0.0203, -0.0124,  0.0008, -0.0373,  0.0148,\n",
      "         0.0321,  0.0068,  0.0318,  0.0032, -0.0166, -0.0267, -0.0053, -0.0364,\n",
      "         0.0008, -0.0261,  0.0357, -0.0334,  0.0209,  0.0075,  0.0049, -0.0215,\n",
      "         0.0028,  0.0230, -0.0031, -0.0002,  0.0163, -0.0368,  0.0330, -0.0069,\n",
      "         0.0362,  0.0208, -0.0098,  0.0251, -0.0383,  0.0403,  0.0099, -0.0148,\n",
      "        -0.0289, -0.0181, -0.0411,  0.0205, -0.0371, -0.0407, -0.0021,  0.0344,\n",
      "        -0.0175, -0.0011, -0.0058,  0.0136,  0.0284,  0.0395,  0.0352,  0.0121,\n",
      "         0.0053, -0.0316,  0.0159,  0.0383,  0.0302, -0.0357,  0.0217,  0.0332,\n",
      "         0.0045,  0.0082, -0.0217, -0.0226, -0.0195,  0.0151, -0.0220, -0.0266,\n",
      "        -0.0179,  0.0270, -0.0309,  0.0259,  0.0273,  0.0217, -0.0107, -0.0073],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([[ 0.0468, -0.0182, -0.0552,  ..., -0.0339,  0.0408, -0.0418],\n",
      "        [-0.0184,  0.0883, -0.0009,  ..., -0.0529,  0.0733,  0.0584],\n",
      "        [-0.0262,  0.0375, -0.0572,  ...,  0.0135,  0.0564, -0.0160],\n",
      "        ...,\n",
      "        [-0.0063, -0.0384, -0.0136,  ..., -0.0338,  0.0553,  0.0842],\n",
      "        [-0.0772,  0.0167, -0.0489,  ...,  0.0550, -0.0160,  0.0267],\n",
      "        [-0.0773, -0.0480,  0.0723,  ..., -0.0265,  0.0802, -0.0862]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([ 0.0345, -0.0571, -0.0045,  0.0507, -0.0007, -0.0595, -0.0547, -0.0530,\n",
      "         0.0489, -0.0164, -0.0557, -0.0797,  0.0592, -0.0514,  0.0488, -0.0547,\n",
      "        -0.0028,  0.0076,  0.0550,  0.0551,  0.0311,  0.0516,  0.0370, -0.0811,\n",
      "         0.0674,  0.0031, -0.0761,  0.0523, -0.0669,  0.0373, -0.0303,  0.0598,\n",
      "         0.0778, -0.0746, -0.0575,  0.0465,  0.0350, -0.0886, -0.0633, -0.0270,\n",
      "         0.0566, -0.0446,  0.0181, -0.0542,  0.0115, -0.0804, -0.0562, -0.0797,\n",
      "        -0.0463, -0.0332, -0.0337, -0.0215,  0.0645,  0.0563,  0.0024,  0.0259,\n",
      "         0.0849, -0.0401, -0.0109,  0.0774, -0.0135, -0.0698, -0.0590, -0.0388,\n",
      "         0.0161,  0.0072, -0.0244, -0.0823, -0.0739, -0.0442, -0.0070,  0.0302,\n",
      "        -0.0206, -0.0459,  0.0658,  0.0227,  0.0219, -0.0445, -0.0719, -0.0625,\n",
      "         0.0622,  0.0736, -0.0712, -0.0608], requires_grad=True), Parameter containing:\n",
      "tensor([[-9.1842e-02, -4.5324e-02, -8.9014e-03,  5.1620e-02,  4.2564e-02,\n",
      "          3.4721e-02, -3.6383e-02, -9.0739e-02, -1.0287e-01, -2.6088e-02,\n",
      "          3.4629e-03, -1.9737e-02, -6.3737e-02,  3.4220e-02,  7.3280e-02,\n",
      "         -2.9387e-02,  4.3215e-02,  2.8835e-02,  6.2197e-02,  7.8017e-02,\n",
      "          1.0215e-01,  1.0728e-01,  7.7774e-02,  8.8817e-02,  1.0637e-01,\n",
      "         -4.9113e-02,  9.6967e-02, -4.4510e-02,  1.8883e-02, -4.9939e-03,\n",
      "          1.1621e-02, -5.2414e-03, -9.9546e-03, -2.6552e-02,  5.2613e-02,\n",
      "         -7.1909e-02,  1.0120e-01,  9.0620e-02, -2.4086e-02,  3.1350e-02,\n",
      "         -5.7355e-02,  9.8745e-02,  2.6056e-02, -2.5387e-02,  1.7810e-02,\n",
      "          5.6658e-02, -8.6981e-02, -1.0335e-01,  6.5393e-02, -6.6746e-02,\n",
      "          2.9958e-02,  1.0344e-01, -2.7981e-02, -7.7223e-02,  6.4179e-04,\n",
      "          4.3998e-02, -2.5036e-02,  1.6055e-03,  1.0550e-01,  6.9700e-02,\n",
      "         -1.0901e-01, -3.8831e-02, -3.2066e-02, -9.3085e-02,  9.8989e-02,\n",
      "         -2.1208e-02,  9.9199e-02, -9.1878e-02, -2.0445e-02, -4.0651e-02,\n",
      "          6.9219e-02,  1.0629e-01, -2.1196e-02,  9.8078e-02,  6.4113e-02,\n",
      "          5.5349e-02, -2.2958e-02, -5.1258e-02, -5.3005e-03, -4.8468e-02,\n",
      "         -3.2851e-02, -2.5354e-02,  4.7283e-03, -8.0255e-02],\n",
      "        [ 5.9971e-02,  6.2076e-02,  7.9321e-02, -2.9544e-02,  3.3443e-02,\n",
      "         -8.0278e-02,  5.9091e-02, -9.7646e-02,  8.4554e-02, -5.2999e-02,\n",
      "          2.2984e-02, -1.3325e-02, -2.0683e-02,  6.0915e-02, -4.3150e-02,\n",
      "          5.6407e-02, -1.9500e-02,  4.9971e-02, -4.8335e-02, -8.2426e-02,\n",
      "         -7.8510e-02, -2.3466e-02,  9.7592e-02, -2.2548e-02, -2.0410e-02,\n",
      "         -5.6532e-02, -5.6458e-02,  9.4062e-03, -1.0527e-01,  7.7838e-03,\n",
      "          3.6312e-02, -5.3958e-02, -1.7773e-02,  3.9895e-02, -5.9657e-02,\n",
      "          4.6162e-02, -4.1342e-02, -3.7029e-02, -2.1844e-02,  1.3688e-02,\n",
      "          4.1396e-02,  1.4805e-03,  3.6943e-03,  9.6238e-02, -5.9037e-02,\n",
      "         -7.4521e-02, -5.0229e-02,  8.1727e-02, -9.8638e-02,  4.9186e-02,\n",
      "          2.4677e-02,  6.1356e-02,  7.3156e-02,  6.1171e-02,  9.6206e-02,\n",
      "         -1.0140e-01,  2.6023e-02,  7.8346e-02, -8.0289e-02,  1.0855e-01,\n",
      "         -3.7002e-02, -1.2286e-02, -6.9899e-02, -4.3660e-02,  1.0591e-01,\n",
      "         -7.5239e-02,  1.2932e-02, -4.8997e-02,  7.1736e-02,  8.2346e-02,\n",
      "          9.6941e-02,  2.9657e-02, -1.4906e-02,  3.9190e-02,  9.5315e-02,\n",
      "         -2.5871e-02,  1.6380e-02,  2.3274e-02, -9.3065e-02, -8.8078e-02,\n",
      "          1.0698e-01,  7.6504e-02, -4.4369e-03, -6.8963e-02],\n",
      "        [-7.3115e-02,  8.3091e-02, -5.6408e-03,  3.4317e-02, -9.3938e-02,\n",
      "         -1.2591e-02,  6.6347e-02, -4.9230e-02,  3.8995e-02, -6.8246e-02,\n",
      "          4.2153e-02,  9.3397e-02, -1.0855e-01,  2.9958e-02, -1.0832e-01,\n",
      "          3.8540e-02, -2.5984e-02, -4.4126e-02,  1.0209e-01, -5.3104e-02,\n",
      "         -4.0784e-02, -1.3427e-03, -9.1787e-02,  2.5795e-02, -1.0692e-01,\n",
      "          1.0213e-01, -1.7120e-02, -1.0272e-01, -8.8572e-03, -8.9391e-02,\n",
      "          9.6703e-02, -1.0374e-02, -1.0608e-01,  4.4725e-02,  5.0199e-02,\n",
      "          7.4644e-02, -4.7084e-02, -5.5134e-02,  1.2205e-02,  1.7233e-02,\n",
      "          6.4647e-02, -7.9360e-02, -2.6496e-02, -1.6280e-02,  1.8171e-02,\n",
      "          4.4046e-02, -6.4190e-02,  1.2401e-02,  7.2703e-02, -1.7069e-02,\n",
      "         -2.7591e-02,  7.1342e-02,  9.1362e-02, -4.1154e-03, -7.1834e-02,\n",
      "          1.2267e-02, -3.9209e-02, -8.6346e-02,  9.1890e-02,  7.1591e-02,\n",
      "         -8.4603e-02, -9.3900e-02,  5.4168e-02,  1.2097e-03,  3.8237e-02,\n",
      "          4.4264e-02, -1.0406e-01, -5.3189e-02, -1.0829e-01, -7.3537e-02,\n",
      "          2.0961e-02,  7.6254e-02,  2.4043e-02,  1.1148e-02, -9.5825e-02,\n",
      "          5.8837e-04,  1.5690e-02, -4.1615e-02,  1.1002e-02,  6.7662e-02,\n",
      "         -6.6980e-02, -3.3284e-02,  1.0104e-01,  1.7589e-02],\n",
      "        [ 5.0963e-02, -5.7017e-02, -4.4670e-02, -7.2506e-02, -2.3541e-02,\n",
      "          7.3982e-02, -4.2978e-02, -3.8606e-02, -9.7905e-02,  8.7013e-02,\n",
      "          8.8247e-02, -8.7514e-02,  6.6615e-02,  8.9305e-02,  6.4461e-02,\n",
      "         -2.2123e-02,  2.2645e-02,  2.1299e-02,  7.4824e-02,  3.5722e-02,\n",
      "          5.8101e-02,  7.1354e-02, -6.8132e-02,  1.0171e-01, -2.0569e-02,\n",
      "         -6.5318e-02, -7.7124e-02, -2.0961e-02,  9.7483e-02, -2.4704e-02,\n",
      "          6.5413e-02,  1.1191e-02,  5.1849e-02,  1.9246e-02,  8.1287e-02,\n",
      "         -4.4671e-02, -8.4347e-02,  6.6549e-02, -8.2458e-02, -2.0566e-02,\n",
      "         -4.7494e-02, -7.9914e-02, -9.2604e-02,  4.4827e-02,  5.8879e-02,\n",
      "          8.1134e-02,  3.3421e-02,  6.3173e-02,  1.0141e-01, -7.8651e-02,\n",
      "          3.1944e-02, -3.0647e-02, -3.8084e-02, -9.9794e-02, -9.2593e-02,\n",
      "         -1.9010e-02, -1.3923e-02, -8.8383e-02,  3.3730e-02,  7.5423e-02,\n",
      "          7.3262e-02, -4.2219e-03, -2.9104e-02,  4.5220e-02, -8.7503e-02,\n",
      "         -2.5417e-02,  1.3356e-02,  2.3670e-02, -5.4348e-02, -5.2864e-02,\n",
      "          7.7580e-02,  9.3918e-02, -6.6115e-02, -3.1825e-02, -8.4712e-02,\n",
      "         -8.2449e-02, -5.3971e-02,  3.2575e-02, -1.0794e-01,  2.2582e-02,\n",
      "          8.8647e-02, -1.0794e-01,  8.4198e-02,  9.9366e-02],\n",
      "        [-8.7103e-03, -1.8064e-02, -5.0364e-02,  2.1081e-02,  7.3821e-02,\n",
      "         -4.0983e-02,  3.5671e-03, -5.3921e-02,  6.1870e-02,  7.2030e-02,\n",
      "         -8.3035e-02,  8.0717e-02,  1.0362e-01, -7.6959e-02, -4.2618e-02,\n",
      "         -3.8416e-02,  6.2250e-03,  1.4656e-02,  2.2046e-02,  1.0351e-01,\n",
      "          1.0404e-01, -8.9326e-02, -2.7113e-02, -1.0635e-01, -7.6118e-02,\n",
      "         -2.9221e-02, -7.4010e-02,  7.1151e-02,  7.9910e-02,  3.6420e-03,\n",
      "          6.0211e-02,  2.0265e-02,  1.0558e-01, -1.0820e-02,  5.1238e-02,\n",
      "          5.1975e-03,  1.0945e-02, -5.8135e-02,  4.4272e-02, -4.5983e-03,\n",
      "          9.4132e-02, -1.6999e-02, -9.3597e-02,  5.3461e-02,  2.3119e-03,\n",
      "          8.4568e-02, -7.5609e-02, -8.9326e-02, -1.0304e-01,  4.6368e-02,\n",
      "         -7.7181e-02,  4.1081e-02,  8.0651e-02,  7.7546e-02,  7.7662e-02,\n",
      "          7.5347e-02,  2.9188e-02,  3.9132e-02, -6.6961e-02,  7.0184e-03,\n",
      "          5.7049e-02, -2.4150e-02,  1.0899e-02,  5.8056e-02, -6.2147e-02,\n",
      "          5.8688e-02,  8.0322e-03,  4.7083e-02, -8.1680e-02, -9.9437e-02,\n",
      "          3.9672e-02,  8.4150e-02, -5.2595e-03,  3.3004e-02, -6.5391e-02,\n",
      "         -1.0637e-01,  8.5179e-02,  1.0037e-01,  7.6368e-02,  1.0027e-01,\n",
      "          5.1305e-02,  6.4685e-02, -9.5663e-02, -5.4585e-02],\n",
      "        [-1.0125e-02, -6.2463e-02,  3.2104e-02,  1.5460e-02, -6.8779e-02,\n",
      "          1.0857e-01,  2.1930e-02,  8.7120e-02,  2.3951e-03,  2.9325e-02,\n",
      "          4.0674e-02,  9.9136e-03,  6.4503e-02,  1.1515e-03, -6.0208e-02,\n",
      "          1.0390e-01, -4.6619e-02,  2.8670e-02, -2.7074e-02,  8.2979e-03,\n",
      "          4.7732e-04,  7.2485e-02, -2.8594e-02,  3.7282e-02,  6.1912e-02,\n",
      "          9.6353e-02,  1.0889e-01,  1.4100e-02,  2.3287e-02,  8.8151e-02,\n",
      "          4.0489e-03,  8.8838e-02, -5.5345e-02,  2.8583e-02,  9.7423e-02,\n",
      "          7.9334e-02,  8.0599e-02,  1.4313e-02, -1.0372e-01,  4.6312e-02,\n",
      "          9.1878e-02,  1.0443e-01,  4.5318e-02,  2.2204e-02,  3.0017e-02,\n",
      "         -3.3391e-02,  3.4315e-02, -7.1041e-02, -8.6496e-03,  6.1640e-02,\n",
      "         -7.3844e-02,  3.6864e-02, -7.7601e-02, -1.0510e-01,  9.4145e-02,\n",
      "          4.1200e-02,  4.3320e-02,  8.6666e-02, -2.4394e-02,  1.8584e-02,\n",
      "         -8.3131e-02, -5.7663e-02,  1.0030e-01, -3.4225e-02, -3.4603e-02,\n",
      "         -2.8673e-02, -4.9767e-02,  7.3130e-02,  6.9977e-02, -2.5924e-02,\n",
      "          1.0523e-01, -2.5252e-02,  8.2193e-02,  9.5175e-02,  3.2923e-02,\n",
      "         -2.5644e-02, -7.0005e-02, -8.3824e-03, -1.5789e-02, -8.5975e-02,\n",
      "          3.6276e-02,  2.5012e-02,  9.0457e-02,  1.0273e-01],\n",
      "        [ 3.3016e-02, -9.4641e-03, -1.5072e-02, -3.5373e-02, -1.0880e-01,\n",
      "         -3.5537e-02,  3.9815e-02, -4.3608e-02, -3.4116e-02,  2.7868e-02,\n",
      "          4.0570e-02, -4.0676e-03,  3.8837e-02,  7.1703e-02,  7.2190e-02,\n",
      "         -6.8185e-02, -2.3403e-02, -5.9403e-02,  2.4437e-02, -6.4704e-02,\n",
      "          7.8885e-03,  8.0373e-02,  5.0521e-02,  3.1676e-02, -2.3130e-02,\n",
      "          6.0026e-02, -1.0251e-01, -9.4043e-02,  9.4814e-02, -5.8037e-02,\n",
      "          1.0124e-01,  2.4271e-03, -6.0486e-02,  5.5150e-02, -5.3991e-02,\n",
      "          8.7571e-02,  8.0095e-03, -8.6275e-02,  1.2608e-02,  1.0598e-01,\n",
      "         -5.8187e-02,  1.0691e-01,  6.7919e-02,  1.0367e-01,  1.2364e-02,\n",
      "         -3.8614e-02,  1.0193e-01, -6.7707e-02,  1.3789e-02, -1.0176e-01,\n",
      "         -5.9150e-02, -1.0688e-01,  9.2533e-02, -8.7398e-04,  7.1699e-02,\n",
      "          4.9843e-02, -3.7032e-02, -3.1088e-02, -7.2821e-02,  5.2814e-02,\n",
      "         -7.0613e-02, -7.3738e-02,  1.1031e-02,  7.9222e-02, -2.3912e-03,\n",
      "         -4.8540e-03,  2.0978e-02,  3.9479e-02, -3.9993e-02, -8.2113e-02,\n",
      "          4.7764e-02, -1.0469e-01, -3.5751e-03, -4.6042e-02,  2.1907e-02,\n",
      "         -2.9525e-02, -7.4925e-02,  7.7087e-02, -6.9052e-02,  3.6347e-02,\n",
      "         -8.7950e-02, -1.4447e-02, -4.0596e-02,  4.6727e-02],\n",
      "        [ 7.1544e-02,  7.0356e-02,  4.3876e-02,  8.9690e-02, -1.0441e-01,\n",
      "         -2.9057e-02, -9.2656e-02, -1.0440e-01,  3.6158e-02,  5.0170e-02,\n",
      "          2.3495e-03, -4.9027e-02, -4.5353e-02, -7.0487e-03,  2.3928e-02,\n",
      "         -8.9375e-02,  2.2094e-02, -6.4155e-02,  6.7241e-02,  7.4690e-02,\n",
      "          7.7710e-02,  4.3549e-02, -2.2990e-02, -6.0082e-02,  6.7434e-02,\n",
      "          5.8160e-02, -8.4725e-02, -9.3583e-02, -8.1359e-02,  2.3765e-02,\n",
      "         -9.2091e-02, -3.3194e-03,  4.5246e-02,  2.8190e-02, -7.9691e-02,\n",
      "         -4.0918e-03, -3.6693e-02, -6.8682e-02,  7.7032e-03,  5.6649e-02,\n",
      "          7.3426e-02,  3.8428e-02,  1.5282e-02, -8.8886e-02,  7.1949e-02,\n",
      "          5.8542e-02,  5.7487e-02, -2.2464e-03, -7.0899e-02,  2.9624e-02,\n",
      "         -1.0465e-01,  6.6390e-02, -8.6253e-02, -6.7452e-02,  4.5122e-02,\n",
      "         -7.4717e-02,  3.9222e-02,  9.2839e-03,  3.5499e-02, -9.5407e-02,\n",
      "         -3.6220e-02,  7.4786e-02, -1.0045e-01,  9.6026e-02, -3.5951e-02,\n",
      "         -8.0661e-02, -6.1135e-02, -4.8996e-02, -4.3975e-02, -6.1600e-02,\n",
      "         -2.9988e-02, -5.0537e-02, -9.2050e-02,  4.2403e-02, -1.0171e-01,\n",
      "         -5.0540e-03,  6.7342e-02, -8.1085e-05,  1.9476e-02,  8.9940e-02,\n",
      "         -9.3425e-03,  2.5372e-02, -1.2206e-02,  5.1773e-03],\n",
      "        [-6.5935e-03, -7.2375e-02, -2.0457e-03,  5.3909e-03, -2.5572e-02,\n",
      "          3.0440e-02, -4.4726e-02,  9.2955e-02, -4.5907e-02,  5.9202e-02,\n",
      "          8.0229e-02,  3.8008e-02,  5.2712e-02,  9.8896e-02,  8.7133e-02,\n",
      "         -1.6598e-02,  4.0183e-02,  6.6529e-02, -8.5236e-02,  3.2213e-02,\n",
      "          1.0855e-01, -4.7706e-02,  3.4153e-02, -4.4178e-02,  1.3034e-02,\n",
      "          1.0067e-01,  2.4994e-02,  8.0996e-03, -1.0606e-01,  2.9017e-02,\n",
      "         -5.1095e-03, -8.3884e-02,  1.0569e-02, -3.8398e-02,  5.3624e-02,\n",
      "          3.7003e-02, -1.0389e-01, -8.1393e-02,  5.7270e-02, -3.3213e-02,\n",
      "         -2.4369e-02,  9.9160e-02,  9.3836e-02,  5.9977e-02, -1.7177e-02,\n",
      "         -1.0275e-01, -9.3913e-02,  9.1975e-02,  4.8226e-02,  4.9656e-02,\n",
      "          2.5873e-02, -8.2109e-03, -7.9532e-03,  5.4100e-02, -4.0008e-02,\n",
      "          1.0483e-01,  1.0140e-01,  2.8226e-02, -1.0113e-01, -4.5385e-02,\n",
      "         -1.0837e-01, -4.1513e-02, -1.0874e-01,  1.9283e-02, -5.9075e-02,\n",
      "          3.0086e-02, -3.5924e-02,  4.1751e-02,  7.0309e-02, -4.2260e-02,\n",
      "          2.3308e-02,  9.3492e-02,  5.9871e-02, -3.9217e-02, -1.3381e-02,\n",
      "          5.5413e-02,  1.0608e-01, -2.3554e-02, -6.6499e-02,  1.5582e-03,\n",
      "         -8.0316e-02, -7.3307e-02,  5.0340e-02,  7.5109e-02],\n",
      "        [-6.0442e-02,  5.2474e-02, -2.0204e-02,  7.9358e-02,  6.6702e-02,\n",
      "          5.9241e-02, -1.7777e-02, -2.0857e-02, -7.7543e-02,  9.7422e-02,\n",
      "         -1.6508e-02, -6.3039e-02,  1.8588e-02, -6.4188e-02, -8.1734e-03,\n",
      "          1.0295e-01, -1.6013e-02, -3.2300e-02,  2.7323e-02,  9.9615e-02,\n",
      "         -5.3957e-02, -5.6238e-02,  6.9722e-02, -7.5218e-02,  9.4185e-02,\n",
      "         -9.8946e-02, -9.3666e-03,  3.0655e-02, -8.0484e-02, -9.6711e-02,\n",
      "          1.1194e-03, -3.3389e-02, -6.9445e-02, -8.8724e-02, -9.9364e-02,\n",
      "         -1.0441e-02, -5.9524e-02, -4.9082e-02, -1.8076e-02,  6.8353e-02,\n",
      "         -5.4056e-02,  8.5135e-02,  1.8095e-02,  3.3832e-02, -9.9349e-02,\n",
      "         -5.3285e-02,  2.1257e-02, -8.9593e-02,  1.7453e-02,  3.2116e-02,\n",
      "         -5.1343e-02, -9.8243e-02,  1.0828e-01,  8.1610e-03, -1.7128e-02,\n",
      "          1.0200e-01, -9.7078e-02, -9.6826e-02, -6.4788e-02,  9.0002e-02,\n",
      "         -1.5774e-02,  9.7521e-02,  1.2210e-02, -7.4431e-02, -3.5557e-02,\n",
      "          9.6077e-02, -1.2418e-02,  1.3533e-02, -6.5420e-02,  7.2254e-02,\n",
      "          3.0359e-02, -1.0467e-01, -5.2716e-02,  3.6925e-02,  8.2295e-02,\n",
      "         -1.3519e-02,  8.0998e-02, -5.4657e-02, -4.3374e-03,  3.4852e-02,\n",
      "         -9.8001e-02, -1.7253e-02, -6.5381e-03,  7.8720e-02]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([ 0.0023, -0.0364,  0.0569,  0.0505, -0.0042, -0.0114, -0.0037,  0.0472,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        -0.0633,  0.0245], requires_grad=True)]\n"
     ]
    }
   ],
   "source": [
    "print(params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "out.backward(torch.randn(1, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.1321, grad_fn=<MseLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "output = net(input)\n",
    "target = torch.randn(10)  # a dummy target, for example\n",
    "target = target.view(1, -1)  # make it the same shape as output\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "loss = criterion(output, target)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Tensor' object has no attribute 'grad_fun'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-30-e917bae2e5ff>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrad_fun\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'Tensor' object has no attribute 'grad_fun'"
     ]
    }
   ],
   "source": [
    "print(loss.grad_fun)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-0.1156,  0.0084,  0.5280,  ..., -0.4433,  1.3025, -1.4785],\n",
       "          [ 0.7296, -0.3683,  0.3157,  ..., -1.1031,  1.4163, -0.1587],\n",
       "          [-1.3868,  1.3393,  0.9328,  ...,  1.4711,  0.2601, -0.2581],\n",
       "          ...,\n",
       "          [-0.6008, -1.8554, -0.3654,  ...,  1.2106, -2.0185, -1.6612],\n",
       "          [-0.0393, -0.9876, -1.8161,  ...,  0.1347,  1.2538, -0.0979],\n",
       "          [ 1.1202,  1.4701,  1.0926,  ..., -1.1245,  0.3872, -0.2298]]]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<MseLossBackward object at 0x000001D9A62A8BE0>\n",
      "<AddmmBackward object at 0x000001D9A62A8C18>\n",
      "<AccumulateGrad object at 0x000001D9A62A8BE0>\n"
     ]
    }
   ],
   "source": [
    "print(loss.grad_fn)  # MSELoss\n",
    "print(loss.grad_fn.next_functions[0][0])  # Linear\n",
    "print(loss.grad_fn.next_functions[0][0].next_functions[0][0])  # ReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1.bias.grad before backward\n",
      "tensor([0., 0., 0., 0., 0., 0.])\n",
      "conv1.bias.grad after backward\n",
      "tensor([-0.0045, -0.0130, -0.0134, -0.0136,  0.0177,  0.0071])\n"
     ]
    }
   ],
   "source": [
    "net.zero_grad()     # zeroes the gradient buffers of all parameters\n",
    "\n",
    "print('conv1.bias.grad before backward')\n",
    "print(net.conv1.bias.grad)\n",
    "\n",
    "loss.backward()\n",
    "\n",
    "print('conv1.bias.grad after backward')\n",
    "print(net.conv1.bias.grad)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "for f in net.parameters():\n",
    "    f.data.sub_(f.grad.data * learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# create your optimizer\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.01)\n",
    "\n",
    "# in your training loop:\n",
    "optimizer.zero_grad()   # zero the gradient buffers\n",
    "output = net(input)\n",
    "loss = criterion(output, target)\n",
    "loss.backward()\n",
    "optimizer.step()    # Does the update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
